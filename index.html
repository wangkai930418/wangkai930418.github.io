<!DOCTYPE html>
<!--[if IE 8]> <html lang="en" class="ie8"> <![endif]-->  
<!--[if IE 9]> <html lang="en" class="ie9"> <![endif]-->  
<!--[if !IE]><!--> <html lang="en"> <!--<![endif]-->  
<head>
    <title>kai wang @ PhD Student</title>
    <!-- Meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Personal website from kai wang">
    <meta name="author" content="kai wang">    
    <link rel="shortcut icon" href="favicon.ico">  
    <link href='http://fonts.googleapis.com/css?family=Lato:300,400,300italic,400italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'> 
    <!-- Global CSS -->
    <link rel="stylesheet" href="assets/plugins/bootstrap/css/bootstrap.min.css">   
    <!-- Plugins CSS -->
    <link rel="stylesheet" href="assets/plugins/font-awesome/css/font-awesome.css">
    <!-- github acitivity css -->
    <link rel="stylesheet" href="http://cdnjs.cloudflare.com/ajax/libs/octicons/2.0.2/octicons.min.css">
    <link rel="stylesheet" href="http://caseyscarborough.github.io/github-activity/github-activity-0.1.0.min.css">
    
    <!-- Theme CSS -->  
    <link id="theme-style" rel="stylesheet" href="assets/css/styles.css">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
    
</head>

<body>
    <!-- ******HEADER****** --> 
    <header class="header">
        <div class="container">                       
            <img class="profile-image img-responsive pull-left" src="assets/images/kai.jpg" alt="kai wang" />
            <div class="profile-content pull-left">
                <h1 class="name">kai wang</h1>
                <h2 class="desc">PhD Candidate at Computer Vision Center</h2>   
                <ul class="social list-inline">
                    <!--<li><a href="https://twitter.com/paurif"><i class="fa fa-twitter"></i></a></li>-->
                    <!--<li><a href="https://www.linkedin.com/in/priba/"><i class="fa fa-linkedin"></i></a></li>-->
                    <li><a href="https://github.com/wangkai930418"><i class="fa fa-github"></i></a></li>
                    <li><a href="https://scholar.google.com/citations?user=j14vd0wAAAAJ&hl=zh-CN"><i class="fa fa-graduation-cap"></i></a></li>
		    <div class="item">
                    <h3 class="title"> <span class="place"><a href="assets/cv/CV.pdf">cv</a></span> <span class="year"></span></h3>
                    </div><!--//item-->

                    <!--<li><a href="mailto:xialei@cvc.uab.es"><i class="fa fa-paper-plane"></i></a></li>-->
                    <!--<li class="last-item"><a href="https://www.reddit.com/user/pribaf/"><i class="fa fa-reddit"></i></a></li>-->
                </ul> 
            </div><!--//profile-->
            <div class="profile-content pull-right" style="vertical-align: middle">
                <a href="http://www.cvc.uab.es"><img src="assets/images/cvc.svg" alt="CVC" width="150px" style="margin: 40px 50px"/></a>
                <a href="http://www.uab.cat"><img src="assets/images/uab.svg" alt="UAB" width="150px" style="margin-top: 20px"/></a>
                <a href="http://www.jlu.edu.cn/"><img src="assets/images/jlu.jpg" alt="JLU" width="100px" style="margin-top: 20px"/></a>
            </div> <!--//institution-->
        </div><!--//container-->
    </header><!--//header-->
    
    <div class="container sections-wrapper">
        <div class="row">
            <div class="primary col-md-8 col-sm-12 col-xs-12">
                
    		
		  <section class="experience section">
                    <div class="section-inner">
                        <h2 class="heading">Latest News</h2>
                        <div class="content">
			    <div class="item">
                              <h3 class="title"> 1 papers is accpted by blabla.
                            </div><!--//item-->
                            
			    
                            
                        </div><!--//content-->  
                    </div><!--//section-inner-->                 
                </section><!--//section-->

		<section class="publications section">
                    <div class="section-inner">
                        <h2 class="heading">Conferences</h2>
                        <div class="content">



                        <!-- ECCV2020 -->
                        <div class="item">
                                <h3 class="title">bookworm continual learning</h3>
                                <!--<h3 class="desc"> <a href="https://arxiv.org/pdf/2003.02567.pdf"> [PDF] </a> <a href="https://arxiv.org/pdf/2003.02567.pdf"> [Code] </a> </h3> -->
                                <ul class="social list-inline">
                                        <li><a href="https://arxiv.org/pdf/2003.02567.pdf"><i class="fa fa-file-pdf-o"></i></a></li>
                                        <li><a href="https://arxiv.org/pdf/2003.02567.pdf"><i class="fa fa-github"></i></a></li>
                                    </ul> 
                                    
                                <p class="authors"><strong>Authors:</strong>Lei Kang, Pau Riba, kai wang, Marçal Rusiñol, Alicia Fornés, Mauricio Villegas</p>
                                <p class="conference">ECCV2020</p>
                                <p id="GANwriting" class="abstract" style="display: none;"><strong>Abstract:</strong> Although current image generation methods have reached impressive quality levels, they are still unable to produce plausible yet diverse images of handwritten words. On the contrary, when writing by hand, a great variability is observed across different writers, and even when analyzing words scribbled by the same individual, involuntary variations are conspicuous. In this work, we take a step closer to producing realistic and varied artificially rendered handwritten words. We propose a novel method that is able to produce credible handwritten word images by conditioning the generative process with both calligraphic style features and textual content. Our generator is guided by three complementary learning objectives: to produce realistic images, to imitate a certain handwriting style and to convey a specific textual content. Our model is unconstrained to any predefined vocabulary, being able to render whatever input word. Given a sample writer, it is also able to mimic its calligraphic features in a few-shot setup. We significantly advance over prior art and demonstrate with qualitative, quantitative and human-based evaluations the realistic aspect of our synthetically produced images.</p>
                                <p><a class="more-link" onclick="myFunction('GANwriting')" href="javascript:void(0);"><i id="GANwriting" class="fa fa-plus"></i> Find out more</a></p>
                            </div><!--//item-->

                        {% comment %} <!-- CVPR2020 -->
                        <div class="item">
                                <h3 class="title">Semi-supervised Learning for Few-shot Image-to-Image Translation</h3>
                                <!--<h3 class="desc"> <a href="https://arxiv.org/pdf/2003.13853.pdf"> [PDF] </a> <a href="https://github.com/yaxingwang/SEMIT"> [Code] </a> </h3> -->
                                <ul class="social list-inline">
                                        <li><a href="https://arxiv.org/pdf/2003.13853.pdf"><i class="fa fa-file-pdf-o"></i></a></li>
                                        <li><a href="https://github.com/yaxingwang/SEMIT"><i class="fa fa-github"></i></a></li>
                                    </ul> 
                                    
                                <p class="authors"><strong>Authors:</strong>kai wang, Salman Khan, Abel Gonzalez-Garcia, Joost van de Weijer, Fahad Shahbaz Khan</p>
                                <p class="conference">CVPR2020</p>
                                <p id="SEMIT" class="abstract" style="display: none;"><strong>Abstract:</strong> In the last few years, unpaired image-to-image translation has witnessed remarkable progress.  Although the latest methods are able to generate realistic images, they crucially rely on a large number of labeled images.  Recently, some methods have tackled the challenging setting of few-shot image-to-image translation, reducing the labeled data requirements for the target domain during inference.  In this work, we go one step further and reduce the amount of required labeled data also from the source domain during training.  To do so, we propose applying semi-supervised learning via a noise-tolerant pseudo-labeling procedure.  We also apply a cycle consistency constraint to further exploit the information from unlabeled images, either from the same dataset or external.  Additionally, we propose several structural modifications to facilitate the image translation task under these circumstances.  Our  semi-supervised method for few-shot image translation, called SEMIT, achieves excellent results on four different datasets using as little as 10% of the source labels, and matches the performance of the main fully-supervised competitor using only 20% labeled data.</p>
                                <p><a class="more-link" onclick="myFunction('SEMIT')" href="javascript:void(0);"><i id="SEMIT" class="fa fa-plus"></i> Find out more</a></p>
                            </div><!--//item--> {% endcomment %}



                                                        
                        </div><!--//content-->  
                    </div><!--//section-inner-->                 
                </section><!--//section-->

                <section class="publications section">
                    <div class="section-inner">
                        <h2 class="heading">Journals</h2>
                        <div class="content">
                            <div class="item">

                        <!-- CVIU -->
                        <div class="item">
                                <h3 class="title">Controlling biases and diversity in diverse image-to-image translation</h3>
                                <!--<h3 class="desc"> <a href="https://arxiv.org/pdf/1907.09754.pdf"> [PDF] </a> <a href="https://arxiv.org/pdf/1907.09754.pdf"> [Code] </a> </h3> -->
                                <ul class="social list-inline">
                                        <li><a href="https://arxiv.org/pdf/1907.09754.pdf"><i class="fa fa-file-pdf-o"></i></a></li>
                                        <li><a href="https://arxiv.org/pdf/1907.09754.pdf"><i class="fa fa-github"></i></a></li>
                                    </ul> 
                                    
                                <p class="authors"><strong>Authors:</strong>kai wang, Abel Gonzalez-Garcia, Luis Herranz, Joost van de Weijer</p>
                                <p class="conference">CVIU</p>
                                <p id="UNIT" class="abstract" style="display: none;"><strong>Abstract:</strong> The task of unpaired image-to-image translation is highly challenging due to the lack of explicit cross-domain pairs of instances.  We consider here diverse image translation (DIT), an even more challenging setting in which an image can have multiple plausible translations.  This is normally achieved by explicitly disentangling content and style in the latent representation and sampling different styles codes while maintaining the image content.  Despite the success of current DIT models, they are prone to suffer from bias.  In this paper, we study the problem of bias in image-to-image translation.  Biased datasets may add undesired changes (e.g. change gender or race in face images) to the output translations as a consequence of the particular underlying visual distribution in the target domain.  In order to alleviate the effects of this problem we propose the use of semantic constraints that enforce the preservation of desired image properties.  Our proposed model is a step towards unbiased diverse image-to-image translation (UDIT), and results in less unwanted changes in the translated images while still performing the wanted transformation.  Experiments on several heavily biased datasets show the effectiveness of the proposed techniques in different domains such as faces, objects, and scenes.</p>
                                <p><a class="more-link" onclick="myFunction('UNIT')" href="javascript:void(0);"><i id="UNIT" class="fa fa-plus"></i> Find out more</a></p>
                            </div><!--//item-->


                            {% comment %} <!-- IJCV -->
                            <div class="item">
                                   <h3 class="title">Mix and match networks: cross-modal alignment for zero-pair image-to-image translation</h3> 
                                   <!--<h3 class="desc"> <a href="https://arxiv.org/abs/1803.03095?context=cs"> [PDF]</a> <a href="https://github.com/xialeiliu/CrowdCountingCVPR18"> [Code] </a> </h3> -->
                                   <ul class="social list-inline">
                                        <li><a href="https://arxiv.org/pdf/1903.04294.pdf"><i class="fa fa-file-pdf-o"></i></a></li>
                                        <li><a href="https://github.com/yaxingwang/Mix-and-match-networks"><i class="fa fa-github"></i></a></li>
                                    </ul> 
                                <p class="authors"><strong>Authors:</strong> kai wang, Joost van de Weijer, Luis Herranz</p>
                                <p class="conference">IJCV</p>
                                <p id="MMNet" class="abstract" style="display: none;"><strong>Abstract:</strong>This paper addresses the problem of infer-ring  unseen  cross-modal  image-to-image  translationsbetween multiple modalities. We assume that only someof the pairwise translations have been seen (i.e. trained)and  infer  the  remaining  unseen  translations  (wheretraining pairs are not available). We propose mix andmatch networks, an approach where multiple encodersand  decoders  are  aligned  in  such  a  way  that  the  de-sired translation can be obtained by simply cascadingthe source encoder and the target decoder, even whenthey have not interacted during the training stage (i.e.unseen).  The  main  challenge  lies  in  the  alignment  ofthe latent representations at the bottlenecks of encoder-decoder  pairs.  We  propose  an  architecture  with  sev-eral  tools  to  encourage  alignment,  including  autoen-coders  and  robust  side  information  and  latent  consis-tency losses. We show the benefits of our approach interms  of  effectiveness  and  scalability  compared  withother pairwise image-to-image translation approaches.We  also  propose  zero-pair  cross-modal  image  transla-tion,  a  challenging  setting  where  the  objective  is  in-ferring  semantic  segmentation  from  depth  (and  vice-versa)  without  explicit  segmentation-depth  pairs,  andonly from two (disjoint) segmentation-RGB and depth-RGB training sets. We observe that a certain part of theshared  information  between  unseen  modalities  mightnot be reachable, so we further propose a variant thatleverages  pseudo-pairs  which  allows  us  to  exploit  thisshared information between the unseen modalities.</p>
                                <p><a class="more-link" onclick="myFunction('MMNet')" href="javascript:void(0);"><i id="liu2018leveraging" class="fa fa-plus"></i> Find out more</a></p>
                            </div><!--//item--> {% endcomment %}


                        </div><!--//content-->  
                    </div><!--//section-inner-->                 
                </section><!--//section-->

                <section class="projects section">
                    <div class="section-inner">
                        <h2 class="heading">Projects</h2>
                        <div class="content">
                            <div class="item">
				<p class="type">M2CR</p>
                                <h3 class="title"><a href="https://projets-lium.univ-lemans.fr/m2cr/">Multimodal Multilingual Continuous Representation for Human Language Understanding</a></h3>
                                <p class="advisors"><strong>Organizators:</strong> Joost van de Weiger,  Loïc Barrault,  Yoshua Bengio</p>
                                <p id="tfm" class="summary" style="display: none;"><strong>Abstract:</strong> This project is dedicated to the creation of a unified neural architecture for multimodal and multilingual human language understanding</p>
                                <p><a class="more-link" onclick="myFunction('tfm')" href="javascript:void(0);"><i id="b_tfm" class="fa fa-plus"></i> Find out more</a></p>
                            </div><!--//item-->
                           
                        </div><!--//content-->  
                    </div><!--//section-inner-->                 
                </section><!--//section-->
                
                <section class="experience section">
                    <div class="section-inner">
                        <h2 class="heading">Experience</h2>
                        <div class="content">
                            <div class="item">
                                <h3 class="title">Support researcher - <span class="place"><a href="http://www.cvc.uab.es">Computer Vision Center</a></span> <span class="year">(Sep 2015 - Now)</span></h3>
                                <p>Collaborate with the Learning and Machine Perception (LAMP) groups at different research projects.</p>
                            </div><!--//item-->
                            
                            <div class="item">
                                <h3 class="title">Hands-on DL with MatConvNet - <span class="place"><a href="http://germanros.net/online-courses/hands-on-dl/"> Hands-on DL</a></span> <span class="year">(12. 2015 - 1. 2016)</span></h3>
                                <p>Collaborate with researchers in CVC </p>
                            </div><!--//item-->

                            <div class="item">
                                <h3 class="title">Candidate of PHD - <span class="place"><a href="http://www.uab.cat/"> Universitat Autònoma de Barcelona</a></span> <span class="year">(Sep 2015 - Sep 2019)</span></h3>
                                <p>PhD scholarship.</p>
                            </div><!--//item-->
			    
                            
                        </div><!--//content-->  
                    </div><!--//section-inner-->                 
                </section><!--//section-->

                <section class="about section">
                    <div class="section-inner">
                        <h2 class="heading">Bio</h2>
                        <div class="content">
                            <p>  I am a postdoctoral with Joost van de Weijer at Computer Vision Center (CVC). I received my PhD degree from engineering school at Autonomous University of Barcelona(UAB) in 2020 under the advisement of  Joost van de Weijer. I received my MS degree in signal processing from Zhengzhou University in 2015. I have worked on a wide variety of projects including images for Encoder-decoder, Transfer Learning, Domain Adaptation, Lifelong Learning.</p>

                        </div><!--//content-->
                    </div><!--//section-inner-->                 
                </section><!--//section-->

            </div><!--//primary-->

            <div class="secondary col-md-4 col-sm-12 col-xs-12">
                 <aside class="info aside section">
                    <div class="section-inner">
                        <h2 class="heading sr-only">Basic Information</h2>
                        <div class="content">
                            <ul class="list-unstyled">
                                <li>
                                    <table style="display: inline;">
                                        <tr>
                                            <td>
                                                <i class="fa fa-map-marker"></i><span class="sr-only">Location:</span>
                                                <br> <br> <br>
                                            </td>
                                            <td>
                                                Computer Vision Center<br>
                                                Edifici O, Universitat Autònoma de Barcelona<br>
                                                08193, Bellaterra, Barcelona, Catalunya
                                            </td>
                                        </tr>
                                    </table>
                                </li>
                                <li><i class="fa fa-phone"></i><span class="sr-only">Phone:</span>+34 652488555</li>
                                <li><i class="fa fa-envelope-o"></i><span class="sr-only">Email:</span>kwang &lt;at&gt; cvc.uab.es</li>
                                <li><i class="fa fa-link"></i><span class="sr-only">Website:</span><a href="http://www.cvc.uab.es/LAMP/">http://www.cvc.uab.es/LAMP/</a></li>
                            </ul>
                        </div><!--//content-->  
                    </div><!--//section-inner-->                 
                </aside><!--//aside-->
                
                <aside class="skills aside section">
                    <div class="section-inner">
                        <h2 class="heading">Skills</h2>
                        <div class="content">
                            <div class="skillset">
                               
                                <div class="item">
                                    <h3 class="level-title">PyTorch<span class="level-label">Proficient</span></h3>
                                    <div class="level-bar">
                                        <div class="level-bar-inner" data-level="95%">
                                        </div>                                      
                                    </div><!--//level-bar-->                                 
                                </div><!--//item-->

                                <div class="item">
                                    <h3 class="level-title">Python<span class="level-label">Proficient</span></h3>
                                    <div class="level-bar">
                                        <div class="level-bar-inner" data-level="95%">
                                        </div>                                      
                                    </div><!--//level-bar-->                                 
                                </div><!--//item-->
                                
                                <div class="item">
                                    <h3 class="level-title">Matlab&Matconvnet<span class="level-label" data-toggle="tooltip" data-placement="left" data-animation="true" title="You can use the tooltip to add more info...">Expert</span></h3>
                                    <div class="level-bar">
                                        <div class="level-bar-inner" data-level="85%">
                                        </div>                                      
                                    </div><!--//level-bar-->                                 
                                </div><!--//item-->
                                

                                <div class="item">
                                    <h3 class="level-title">C/C++<span class="level-label">Proficient</span></h3>
                                    <div class="level-bar">
                                        <div class="level-bar-inner" data-level="80%">
                                        </div>                                      
                                    </div><!--//level-bar-->                                 
                                </div><!--//item-->

                                
                                <!--<p><a class="more-link" href="#"><i class="fa fa-external-link"></i> More on Coderwall</a></p> -->
                            </div>              
                        </div><!--//content-->  
                    </div><!--//section-inner-->                 
                </aside><!--//section-->
                               
                <aside class="education aside section">
                    <div class="section-inner">
                        <h2 class="heading">Education</h2>
                        <div class="content">
                            <div class="item">                      
                                <h3 class="title"><i class="fa fa-graduation-cap"></i> PhD in Computer Vision</h3>
                                <h4 class="university">Universitat Autònoma de Barcelona</h4>
                                <h4 class="university">Computer Vision Center</h4>
                                <h4 class="year">(2015-Now)</h4>
                           </div><!--//item-->
                           <div class="item">                      
                                <h3 class="title"><i class="fa fa-graduation-cap"></i> MSc in Image Processing</h3>
                                <h4 class="university">Jilin University</h4>
                                <h4 class="year">(2012-2015)</h4>
                            </div><!--//item-->

                        </div><!--//content-->
                    </div><!--//section-inner-->
                </aside><!--//section--> 
                            
                <aside class="languages aside section">
                    <div class="section-inner">
                        <h2 class="heading">Languages</h2>
                        <div class="content">
                            <ul class="list-unstyled">
                                <li class="item">
                                    <span class="title"><strong>Chinese:</strong></span>
                                    <span class="level">Native Speaker <br class="visible-xs"/><i class="fa fa-star"></i> <i class="fa fa-star"></i> <i class="fa fa-star"></i> <i class="fa fa-star"></i> <i class="fa fa-star"></i> </span>
                                </li><!--//item-->
                            
                                <li class="item">
                                    <span class="title"><strong>English:</strong></span>
                                    <span class="level">Professional Proficiency <br class="visible-sm visible-xs"/><i class="fa fa-star"></i> <i class="fa fa-star"></i> <i class="fa fa-star"></i> <i class="fa fa-star"></i> <i class="fa fa-star-o" aria-hidden="true"></i></span>
                                </li><!--//item-->

			                    <li class="item">
                                    <span class="title"><strong>Spanish:</strong></span>
                                    <span class="level">Beginner <br class="visible-sm visible-xs"/><i class="fa fa-star"></i> <i class="fa fa-star"></i> <i class="fa fa-star-o"></i> <i class="fa fa-star-o"></i> <i class="fa fa-star-o" aria-hidden="true"></i></span>
                                </li><!--//item-->
                            </ul>
                        </div><!--//content-->
                    </div><!--//section-inner-->
                </aside><!--//section-->



                <aside class="habits aside section">
                    <div class="section-inner">
                        <h2 class="heading">Habits</h2>
                        <div class="content">
                            <p> Powerlifting, Reading on history </p>
                        </div><!--//content-->
                    </div><!--//section-inner-->
                </aside><!--//section-->





            </div><!--//secondary-->    
        </div><!--//row-->
    </div><!--//masonry-->

    <!-- ******GO TO TOP****** -->
    <button onclick="topFunction()" id="go2top" title="Go to top"><i class="fa fa-address-card" style="font-size: 2em"></i></button> 

    <!-- ******FOOTER****** --> 
    <footer class="footer">
        <div class="container text-center">
                <small class="copyright">Designed with <i class="fa fa-heart"></i> by <a href="http://themes.3rdwavemedia.com" target="_blank">3rd Wave Media</a> for developers under the <a class="dotted-link" href="http://creativecommons.org/licenses/by/3.0/" target="_blank">Creative Commons Attribution 3.0 License</a> <a href="http://themes.3rdwavemedia.com/website-templates/free-responsive-website-template-for-developers/" target="_blank"><i class="fa fa-download"></i></a></small>
        </div><!--//container-->
    </footer><!--//footer-->

    <!-- Javascript -->          
    <script type="text/javascript" src="assets/plugins/jquery-1.11.1.min.js"></script>
    <script type="text/javascript" src="assets/plugins/jquery-migrate-1.2.1.min.js"></script>
    <script type="text/javascript" src="assets/plugins/bootstrap/js/bootstrap.min.js"></script>    
    <script type="text/javascript" src="assets/plugins/jquery-rss/dist/jquery.rss.min.js"></script> 
    <script>
	function myFunction(id) {
	    var x = document.getElementById(id);
            var b = document.getElementById("b_".concat(id));
	    if (x.style.display === 'none') {
		x.style.display = 'block';
                b.className = "fa fa-minus"
	    } else {
		x.style.display = 'none';
		b.className = "fa fa-plus"
	    }
	}
    </script>
    <!-- GO TO TOP -->
    <script>
    // When the user scrolls down 20px from the top of the document, show the button
    window.onscroll = function() {scrollFunction()};

    function scrollFunction() {
        if (document.body.scrollTop > 2000 || document.documentElement.scrollTop > 2000) {
            document.getElementById("go2top").style.display = "block";
        } else {
            document.getElementById("go2top").style.display = "none";
        }
    }

    // When the user clicks on the button, scroll to the top of the document
    function topFunction() {
        document.body.scrollTop = 0; // For Chrome, Safari and Opera
        document.documentElement.scrollTop = 0; // For IE and Firefox
    } 
    </script>
    <!-- github activity plugin -->
    <script type="text/javascript" src="http://cdnjs.cloudflare.com/ajax/libs/mustache.js/0.7.2/mustache.min.js"></script>
    <script type="text/javascript" src="http://caseyscarborough.github.io/github-activity/github-activity-0.1.0.min.js"></script>
    <!-- custom js -->
    <script type="text/javascript" src="assets/js/main.js"></script>            
</body>
</html> 

