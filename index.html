<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<!-- saved from url=(0023)https://jonbarron.info/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="“width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 24px;
    }
    subtitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 18px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="https://jonbarron.info/seal_icon.png">
  <title>Kai Wang</title>
  
  <link href="./QingnanFan_files/css" rel="stylesheet" type="text/css">
  <script charset="utf-8" src="chrome-extension://jgphnjokjhjlcnnajmfjlacjnjkhleah/js/btype.js"></script></head>

  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody><tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="100%" valign="middle">
        <p align="center">
          <name>Kai Wang</name>
        </p>
        <p>
        I'm now working as a PostDoc in <a href="http://www.cvc.uab.es/">LAMP group</a> at Computer Vision Center (CVC), UAB. 
        Before that I graduate as a PhD under the supervision of Joost van de Weijer in 2022. 
        I received my master degree in image processing from Jilin University in 2017 and the bachelor degree from Jilin University in 2014. 
        I have worked on a wide variety of projects including Diffusion Models, Continual Learning and Vision Transformers.
        Now I am mainly working on multiple projects on diffusion models and supervising several <a href="https://scholar.google.com/citations?user=vf7PeaoAAAAJ&hl=zh-CN">PhD students</a> on related topics.

        <p align="center">
          <a href="mailto:kwang@cvc.uab.es">Email</a> &nbsp/&nbsp
          <!-- <a href="./QingnanFan_files/qingnan_cv.pdf">CV</a> &nbsp/&nbsp -->
          <!-- <a href="./QingnanFan_files/Qingnan-bio.txt">Biography</a> &nbsp/&nbsp -->
          <a href="https://scholar.google.com/citations?user=j14vd0wAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
          <a href="https://www.linkedin.com/in/kai-wang-43129b1b7/">LinkedIn</a> &nbsp/&nbsp
          <a href="https://twitter.com/Alvaro_kai93">Twitter</a> &nbsp/&nbsp
          <a href="https://github.com/wangkai930418">Github</a> &nbsp/&nbsp
          <a href="https://github.com/wangkai930418/awesome-diffusion-categorized">Awesome Diffusion</a>
        </p>
        </td>
        <td width="33%">
        <img src="figs/kai.jpg" width="125" alt="" style="border-style: none" align="middle">
        </td>
      </tr>
      </tbody></table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="100%" valign="middle">
          <strong><heading>Publications</heading></strong>
          <!-- <p>
            My research focus lies in computer graphics, 3D vision, image processing, and human-computer interaction. My recent effort has been spent on pushing the limit of 3D vision and reinforcement learning technologies to implement an intelligent embodied agent in both forms of physical robots and digital humans. 
          </p> -->
        </td>
      </tr>
      </tbody></table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

        
        <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
          <td width="25%">
            <div class="one">
            <div class="two" id="portrait_image" style="opacity: 0;">
            <img src="figs/locinv.png" width="175" alt="" style="border-style: none" align="middle">
            </div>
            <img src="figs/locinv.png" width="175" alt="" style="border-style: none" align="middle">
            </div>
            <script type="text/javascript">
            function portrait_start() {
            document.getElementById('portrait_image').style.opacity = "1";
            }
            function portrait_stop() {
            document.getElementById('portrait_image').style.opacity = "0";
            }
            portrait_stop()
            </script>
          </td>
          <td valign="top" width="75%">
              <papertitle>LocInv: Localization-aware Inversion for Text-Guided Image Editing</papertitle>
        <br>     
        <a href="https://scholar.google.com/citations?user=BiRPM9AAAAAJ&hl=en&oi=sra">Chuanming Tang</a>, 
        <strong>Kai Wang*</strong>, 
        <a href="https://scholar.google.com/citations?user=S1gksNwAAAAJ&hl=zh-CN">Fei Yang</a>, 
        <a href="http://lamp.cvc.uab.es/">Joost van de Weijer</a>.
        <br>
            <em>CVPR AI4CC workshop</em>, 2024</strong><br>
            <a href="https://github.com/wangkai930418/DPL" target="_blank">project page</a>
            <!-- /
            <a href="./QingnanFan_files/tog_2023_supp.pdf" target="_blank">supp file</a> -->
            /
            <a href="https://arxiv.org/abs/2405.01496" target="_blank">arXiv</a>
            <p></p>
            <p> We address the cross-attention leakage problem in Text-to-Image diffusion model inversions by introducing the localization priors.</p>
          </td>
        </tr>


        <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
          <td width="25%">
            <div class="one">
            <div class="two" id="portrait_image" style="opacity: 0;">
            <img src="figs/keypoint_detect.png" width="175" alt="" style="border-style: none" align="middle">
            </div>
            <img src="figs/keypoint_detect.png" width="175" alt="" style="border-style: none" align="middle">
            </div>
            <script type="text/javascript">
            function portrait_start() {
            document.getElementById('portrait_image').style.opacity = "1";
            }
            function portrait_stop() {
            document.getElementById('portrait_image').style.opacity = "0";
            }
            portrait_stop()
            </script>
          </td>
          <td valign="top" width="75%">
            <!-- <a href="./QingnanFan_files/siga_2023.pdf"> -->
              <papertitle>Diffusion-based network for unsupervised landmark detection</papertitle>
            <!-- </a> -->
        <br>     
        Tao Wu,
        <strong>Kai Wang*</strong>, 
        <a href="https://scholar.google.com/citations?user=BiRPM9AAAAAJ&hl=en&oi=sra">Chuanming Tang</a>, 
        Jianlin Zhang.
        <br>
            <em>Knowledge-Based Systems</em>, 2024</strong><br>
            <a href="https://www.sciencedirect.com/science/article/abs/pii/S0950705124002624" target="_blank">Journal</a>
            <!-- / -->
            <!-- <a href="https://frank-zy-dou.github.io/projects/CASE/index.html" target="_blank">project page</a>
            /
            <a href="https://youtu.be/Cgq6JbQ1VW4" target="_blank">video</a>
            /
            <a href="./QingnanFan_files/siga_2023.bib">bibtex</a> -->
            <p></p>
            <p> We propose a novel diffusion-based network (DBN) for unsupervised landmark detection, which leverages the generation ability of the diffusion models to detect the landmark locations.</p>
          </td>
        </tr>
   
        
        <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
        <td width="25%">
            <div class="one">
            <div class="two" id="portrait_image" style="opacity: 0;">
            <img src="figs/iterinv.png" width="175" alt="" style="border-style: none" align="middle">
            </div>
            <img src="figs/iterinv.png" width="175" alt="" style="border-style: none" align="middle">
            </div>
            <script type="text/javascript">
            function portrait_start() {
            document.getElementById('portrait_image').style.opacity = "1";
            }
            function portrait_stop() {
            document.getElementById('portrait_image').style.opacity = "0";
            }
            portrait_stop()
            </script>
        </td>
        <td valign="top" width="75%">
        <!-- <a href="./QingnanFan_files/cvpr_2023.pdf"> -->
                <papertitle>IterInv: Iterative Inversion for Pixel-Level T2I Models</papertitle>
        <!-- </a> -->
        <br>     
        <a href="https://scholar.google.com/citations?user=BiRPM9AAAAAJ&hl=en&oi=sra">Chuanming Tang</a>, 
        <strong>Kai Wang*</strong>, 
        <a href="http://lamp.cvc.uab.es/">Joost van de Weijer</a>.
        <br>
            <em>ICME</em>, 2024 & NeurIPS 2023 workshop on Diffusion Models </strong><br>
            <a href="https://github.com/Tchuanm/IterInv" target="_blank">project page</a>
            /
            <a href="https://arxiv.org/abs/2310.19540" target="_blank">arXiv</a>
            <!-- /
            <a href="./QingnanFan_files/cvpr_2023.bib">bibtex</a> -->
            <p></p>
            <p>  We develop an iterative inversion (IterInv) technique for the pixel level T2I models and verify IterInv with the open-source DeepFloyd-IF model.</p>
        </td>
        </tr>

        
        <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
            <td width="25%">
                <div class="one">
                <div class="two" id="portrait_image" style="opacity: 0;">
                <img src="figs/pocon.png" width="175" alt="" style="border-style: none" align="middle">
                </div>
                <img src="figs/pocon.png" width="175" alt="" style="border-style: none" align="middle">
                </div>
                <script type="text/javascript">
                function portrait_start() {
                document.getElementById('portrait_image').style.opacity = "1";
                }
                function portrait_stop() {
                document.getElementById('portrait_image').style.opacity = "0";
                }
                portrait_stop()
                </script>
            </td>
            <td valign="top" width="75%">
            <!-- <a href="./QingnanFan_files/cvpr_2023.pdf"> -->
                    <papertitle>Plasticity-Optimized Complementary Networks for Unsupervised Continual Learning</papertitle>
            <!-- </a> -->
            <br>     
            <a href="https://scholar.google.com/citations?user=A2dhwNgAAAAJ&hl=zh-CN">Alex Gomez-Villa</a>, 
            <a href="https://scholar.google.com/citations?user=8yywECgAAAAJ&hl=zh-CN">Bartlomiej Twardowski</a>, 
            <strong>Kai Wang*</strong>, 
            <a href="http://lamp.cvc.uab.es/">Joost van de Weijer</a>.
            <br>
                <em>WACV</em>, 2024 </strong><br>
                <a href="https://github.com/alviur/pocon_wacv2024" target="_blank">project page</a>  
                /
                <a href="https://arxiv.org/abs/2309.06086" target="_blank">arXiv</a>
                <p></p>
                <p> In this continual learning paper, we propose to train an expert network that is relieved of the duty of keeping the previous knowledge and can focus on performing optimally on the new tasks (optimizing plasticity).</p>
            </td>
            </tr>

            <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
                <td width="25%">
                    <div class="one">
                    <div class="two" id="portrait_image" style="opacity: 0;">
                    <img src="figs/dpl.png" width="175" alt="" style="border-style: none" align="middle">
                    </div>
                    <img src="figs/dpl.png" width="175" alt="" style="border-style: none" align="middle">
                    </div>
                    <script type="text/javascript">
                    function portrait_start() {
                    document.getElementById('portrait_image').style.opacity = "1";
                    }
                    function portrait_stop() {
                    document.getElementById('portrait_image').style.opacity = "0";
                    }
                    portrait_stop()
                    </script>
                </td>
                <td valign="top" width="75%">
                <!-- <a href="./QingnanFan_files/cvpr_2023.pdf"> -->
                        <papertitle>Dynamic Prompt Learning: Addressing Cross-Attention Leakage for Text-Based Image Editing</papertitle>
                <!-- </a> -->
                <br>     
                <strong>Kai Wang*</strong>, 
                <a href="https://scholar.google.com/citations?user=S1gksNwAAAAJ&hl=zh-CN&oi=sra">Fei Yang</a>, 
                <a href="https://www.shiqiyang.xyz/">Shiqi Yang</a>, 
                <a href="https://scholar.google.com/citations?user=vf7PeaoAAAAJ&hl=zh-CN&oi=sra">Muhammad Atif Butt</a>, 
                <a href="http://lamp.cvc.uab.es/">Joost van de Weijer</a>.
                <br>
                    <em>NeurIPS</em>, 2023 </strong><br>
                    <a href="https://github.com/wangkai930418/DPL" target="_blank">project page</a>  
                    /
                    <a href="https://arxiv.org/abs/2309.15664" target="_blank">arXiv</a>
                    <p></p>
                    <p> In this paper, we propose Dynamic Prompt Learning (DPL) to force cross-attention maps to focus on correct noun words in the text prompt.
                        By updating the dynamic tokens for nouns in the textual input with the proposed leakage repairment losses,
                        we achieve fine-grained image editing over particular objects while preventing undesired changes to other image regions.</p>
                </td>
                </tr>

                <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
                    <td width="25%">
                        <div class="one">
                        <div class="two" id="portrait_image" style="opacity: 0;">
                        <img src="figs/scrollnet.gif" width="175" alt="" style="border-style: none" align="middle">
                        </div>
                        <img src="figs/scrollnet.gif" width="175" alt="" style="border-style: none" align="middle">
                        </div>
                        <script type="text/javascript">
                        function portrait_start() {
                        document.getElementById('portrait_image').style.opacity = "1";
                        }
                        function portrait_stop() {
                        document.getElementById('portrait_image').style.opacity = "0";
                        }
                        portrait_stop()
                        </script>
                    </td>
                    <td valign="top" width="75%">
                    <!-- <a href="./QingnanFan_files/cvpr_2023.pdf"> -->
                            <papertitle>ScrollNet: Dynamic Weight Importance for Continual Learning</papertitle>
                    <!-- </a> -->
                    <br>     
                    <a href="https://scholar.google.com/citations?user=S1gksNwAAAAJ&hl=zh-CN&oi=sra">Fei Yang</a>, 
                    <strong>Kai Wang*</strong>, 
                    <a href="http://lamp.cvc.uab.es/">Joost van de Weijer</a>.
                    <br>
                        <em>ICCV VCL workshop</em>, 2023 </strong><br>
                        <a href="https://github.com/firefyf/scrollnet" target="_blank">project page</a>  
                        /
                        <a href="https://arxiv.org/abs/2308.16567" target="_blank">arXiv</a>
                        <p></p>
                        <p> In this paper, we propose ScrollNet as a scrolling neural network for continual learning. 
                            ScrollNet can be seen as a dynamic network that assigns the ranking of weight importance for each task before data exposure, 
                            thus achieving a more favorable stability-plasticity tradeoff during sequential task learning by reassigning this ranking for different tasks.</p>
                    </td>
                    </tr>

                    <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
                        <td width="25%">
                            <div class="one">
                            <div class="two" id="portrait_image" style="opacity: 0;">
                            <img src="figs/dwopp.png" width="175" alt="" style="border-style: none" align="middle">
                            </div>
                            <img src="figs/dwopp.png" width="175" alt="" style="border-style: none" align="middle">
                            </div>
                            <script type="text/javascript">
                            function portrait_start() {
                            document.getElementById('portrait_image').style.opacity = "1";
                            }
                            function portrait_stop() {
                            document.getElementById('portrait_image').style.opacity = "0";
                            }
                            portrait_stop()
                            </script>
                        </td>
                        <td valign="top" width="75%">
                        <!-- <a href="./QingnanFan_files/cvpr_2023.pdf"> -->
                                <papertitle>Positive Pair Distillation Considered Harmful: Continual Meta Metric Learning for Lifelong Object Re-Identification</papertitle>
                        <!-- </a> -->
                        <br>     
                        <strong>Kai Wang*</strong>, 
                        <a href="https://scholar.google.com/citations?user=FO7GyVwAAAAJ&hl=en">Chenshen Wu</a>, 
                        <a href="https://scholar.google.com/citations?user=_Fk4YUcAAAAJ&hl=zh-CN">Andrew D. Bagdanov</a>, 
                        <a href="https://mmcheng.net/xliu/">Xialei Liu</a>, 
                        <a href="https://www.shiqiyang.xyz/">Shiqi Yang</a>, 
                        <a href="http://lamp.cvc.uab.es/">Joost van de Weijer</a>.
                        <br>
                            <em>BMVC</em>, 2022 </strong><br>
                            <a href="https://github.com/wangkai930418/DwoPP_code" target="_blank">project page</a>  
                            /
                            <a href="https://arxiv.org/abs/2210.01600" target="_blank">arXiv</a>
                            <p></p>
                            <p> To address the incremental Person ReID problem, 
                                we apply continual meta metric learning to lifelong object re-identification. 
                                To prevent forgetting of previous tasks, 
                                we use knowledge distillation and explore the roles of positive and negative pairs. 
                                Based on our observation that the distillation and metric losses are antagonistic, 
                                we propose to remove positive pairs from distillation to robustify model updates.</p>
                        </td>
                        </tr>

<!-- 

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr>
      <td width="100%" valign="middle">
        <strong><heading>Work experience</heading></strong>
      </td>
    </tr>
    </tbody></table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="25%">
          <img src="./QingnanFan_files/vivo.jpg" width="110" alt="" style="border-style: none" align="right">
        </td>
        <td valign="top" width="75%">
          <papertitle>VIVO</papertitle>
          <br>
          Lead Researcher
          <br>
          2023-now
        </td>
      </tr>

      <tr>
        <td width="25%">
          <img src="./QingnanFan_files/tencent.png" width="110" alt="" style="border-style: none" align="right">
        </td>
        <td valign="top" width="75%">
          <papertitle>Tencent AI Lab</papertitle>
          <br>
          Senior Researcher
          <br>
          2021-2023
        </td>
      </tr>
  </table> -->


  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr>
      <td width="100%" valign="middle">
        <strong><heading>Education</heading></strong>
      </td>
    </tr>
    </tbody></table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="25%">
          <img src="figs/uab_logo.png" width="110" alt="" style="border-style: none" align="right">
        </td>
        <td valign="top" width="75%">
          <papertitle>Universitat Autònoma de Barcelona</papertitle>
          <br>
          Postdoctoral Researcher
          <br>
          Supervised by Prof. Joost van de Weijer
          <br>
          2022-2024
        </td>
      </tr>

      <tr>
        <td width="25%">
          <img src="figs/uab_logo.png" width="110" alt="" style="border-style: none" align="right">
        </td>
        <td valign="top" width="75%">
          <papertitle>Universitat Autònoma de Barcelona</papertitle>
          <br>
          Ph.D. student
          <br>
          Supervised by Prof. Joost van de Weijer
          <br>
          2017-2022
        </td>
      </tr>

      <tr>
        <td width="25%">
          <img src="figs/jilin_univ_logo.jpeg" width="110" alt="" style="border-style: none" align="right">
        </td>
        <td valign="top" width="75%">
          <papertitle>Jilin University</papertitle>
          <br>
          Undergraduate student and Master student
          <br>
          2010-2017
        </td>
      </tr>
  </table>


  <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr>
      <td width="100%" valign="middle">
        <strong><heading>Research experience</heading></strong>
      </td>
    </tr>
    </tbody></table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">



    <tr>
      <td width="25%">
        <img src="./QingnanFan_files/cambridge.jpg" width="110" alt="" style="border-style: none" align="right">
      </td>
      <td valign="top" width="75%">
        <papertitle>University of Cambridge</papertitle>
        <br>
        Visiting Student
        <br>
        Supervised by Prof. Carola-Bibiane Schönlieb
        <br>
        2018
      </td>
    </tr>

    <tr>
      <td width="25%">
        <img src="./QingnanFan_files/msra.png" width="110" alt="" style="border-style: none" align="right">
      </td>
      <td valign="top" width="75%">
        <papertitle>Microsoft Research Asia</papertitle>
        <br>
        Research Intern
        <br>
        Supervised by Gang Hua, Xin Tong, Jiaolong Yang and David Wipf
        <br>
        2016-2018
      </td>
    </tr>
=


  </table>

<!-- 
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr>
      <td width="100%" valign="middle">
        <strong><heading>Talks</heading></strong>
        <p>APR. 2022: Active 3D scene understanding and its applications
          <br>“三维视觉与智能图形”前沿论坛, 图图名师讲堂, China
        </p>

        <p>OCT. 2021: Visual Localization
          <br>Embodied AI Workshop, Valse, China
        </p>

        <p>JAN. 2019: Deep Learning in Computational Photography
          <br>USC ICT/UW Reality Lab/Berkeley/Stanford/Google/MSR, US
        </p>  

        <p>DEC. 2018: Deep Learning for Single Image Artifact Removal
          <br>ACCV Tutorial 2018, Australia
        </p>

        <p>DEC. 2018: Image Smoothing via Unsupervised Learning
          <br>SIGGRAPH Asia 2018, Japan; GAMES Webinar, China
        </p>

        <p>AUG. 2018: Discovering Unsupervised Learning in Image Processing
          <br>CIA, Cambridge University, UK
        </p>

        <p>JUN. 2018: Revisiting Deep Intrinsic Image Decomposition
          <br>CVPR 2018, USA
        </p>

        <p>NOV. 2015: Interactive Real-time Video Segmentation
          <br>SIGGRAPH Asia 2015, Japan
        </p>
      </td>
    </tr>
    </tbody></table>


  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr>
      <td width="100%" valign="middle">
        <strong><heading>Awards</heading></strong>
        <p>2022: Tencent Outstanding Contributor</p>
        <p>2020: CCF Doctorial Dissertation Award Nominee (CCF 优博提名)</p>
        <p>2019: Outstanding Academic Achievement Award of Shandong University</p>
        <p>2018: Academic Star Nominee of Shandong University (10/20000)</p>
        <p>2018: National Scholarship</p>
        <p>2016: Outstanding Academic Achievement Award of Shandong University</p>
        <p>2015: Presidential Scholarship of Shandong University (35/20000)
        (Highest honor for students in SDU, only 35 elected among around 20000 candidates)</p>
        <p>2015: National Scholarship</p>
        <p>2015: Pacemaker to Outstanding Graduate Student of Shandong University</p>
      </td>
    </tr>
    </tbody></table> -->


  <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr>
      <td width="100%" valign="middle">
        <heading>Mentored students</heading>
          <p>Qihang Fang (PhD student in University of Hong Kong)</p>
          <p>Siyan Dong (PostDoc in University of Hong Kong)</p>
          <p>Yingda Yin (PhD student in Peking University)</p>
          <p>Kai Ye (PhD student in Peking University)</p>
          <p>Jiazhao Zhang (PhD student in Peking University)</p>
          <p>Yunze Liu (PhD student in Tsinghua University)</p>
          <p>Yijia Weng (PhD student in Stanford University)</p>
          <p>Jialei Huang (PhD student in Tsinghua University)</p>
          <p>Guanqi Zhan (PhD student in Oxford University)</p>
      </td>
    </tr>
    </tbody></table> -->
  

</body></html>